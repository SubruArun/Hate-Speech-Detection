{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All Shallow Models",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doACOG38-cx-"
      },
      "source": [
        "**Gaussian Naive Bayes ( Without PCA )**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypaTrObR96X-"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import os\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "dataset=pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/unigramSvmInput/hate.csv')\n",
        "#print(dataset)\n",
        "\n",
        "X = dataset.drop('class',axis=1)\n",
        "y = dataset['class']\n",
        "\n",
        "\n",
        "#y = dataset['class']\n",
        "#print(X.shape)\n",
        "#print(y.shape)\n",
        "\n",
        "\n",
        "# initiate PCA and classifier\n",
        "#pca = PCA()\n",
        "classifier = GaussianNB()\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.3,random_state=4)\n",
        "\n",
        "# transform / fit \n",
        "#X_transformed = pca.fit_transform(X_train)\n",
        "#print(len(X_train))\n",
        "#print(len(X_test))\n",
        "\n",
        "#training\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "#gs_clf = gs_clf.fit(X_train, y_train)\n",
        "\n",
        "# predict \"new\" data\n",
        "# transform new data using already fitted pca\n",
        "#X is projected on the first principal components previously extracted from a training set.\n",
        "#newdata_transformed = pca.transform(X_test)\n",
        "\n",
        "# predict labels using the trained classifier\n",
        "pred_labels = classifier.predict(X_test)\n",
        "print(pred_labels)\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y,pred_labels))\n",
        "print(\"\\n\\n\\n..................................COMPLETED...............................\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDxfZgrgAn7r"
      },
      "source": [
        "\n",
        "**Gaussian Naive Bayes ( With PCA )**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt-LAHj-AvXC"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import os\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "dataset=pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/unigramSvmInput/hate.csv')\n",
        "#print(dataset)\n",
        "\n",
        "X = dataset.drop('class',axis=1)\n",
        "y = dataset['class']\n",
        "\n",
        "\n",
        "#y = dataset['class']\n",
        "#print(X.shape)\n",
        "#print(y.shape)\n",
        "\n",
        "\n",
        "# initiate PCA and classifier\n",
        "pca = PCA()\n",
        "classifier = GaussianNB()\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.3,random_state=4)\n",
        "\n",
        "# transform / fit \n",
        "X_transformed = pca.fit_transform(X_train)\n",
        "#print(len(X_train))\n",
        "#print(len(X_test))\n",
        "\n",
        "#training\n",
        "classifier.fit(X_transformed, y_train)\n",
        "\n",
        "#gs_clf = gs_clf.fit(X_train, y_train)\n",
        "\n",
        "# predict \"new\" data\n",
        "# transform new data using already fitted pca\n",
        "#X is projected on the first principal components previously extracted from a training set.\n",
        "newdata_transformed = pca.transform(X_test)\n",
        "\n",
        "# predict labels using the trained classifier\n",
        "pred_labels = classifier.predict(newdata_transformed)\n",
        "print(pred_labels)\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y,pred_labels))\n",
        "print(\"\\n\\n\\n..................................COMPLETED...............................\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV0V7CZlBOvD"
      },
      "source": [
        "**Gaussian Naive Bayes ( With TFIDF )**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNIOQLgaBQ1a"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "'''\n",
        "clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf',GaussianNB()),\n",
        "])\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "dataset=pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/naive inp.csv')\n",
        "#print(dataset)\n",
        "\n",
        "# Function to remove blank spaces(Starting)\n",
        "def removeSpaces(dataset):\n",
        "  ret = []\n",
        "  for data in dataset:\n",
        "    ret.append(data.strip())\n",
        "\n",
        "  return ret\n",
        "\n",
        "x = dataset.drop('class',axis=1)\n",
        "x = list(x[\"tweet\"])\n",
        "X = removeSpaces(x)\n",
        "y = list(dataset['class'])\n",
        "#y = np.array(y)\n",
        "\n",
        "\n",
        "clf = GaussianNB()\n",
        "\n",
        "vect = CountVectorizer()\n",
        "X_count = vect.fit_transform(X)\n",
        "\n",
        "tfidf = TfidfTransformer()\n",
        "X_tf = tfidf.fit_transform(X_count)\n",
        "\n",
        "#print(X_tf.shape)\n",
        "#X_ = X_tf.toarray()\n",
        "y_ = np.array(y)\n",
        "X_tf = X_tf.toarray()\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_tf, y_,test_size=0.3,random_state=4)\n",
        "\n",
        "#training\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "#Validation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,clf.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFf0nZzmC3qk"
      },
      "source": [
        "SVM(Without PCA)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxpeHFNnDBRx"
      },
      "source": [
        "'''!apt-get -qq install request\n",
        "!apt-get -qq install pandas'''\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/unigramSvmInput/offensive.csv')\n",
        "#dataset.drop(dataset.columns[dataset.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "#print(dataset)\n",
        "x = dataset.drop('lab_el', axis=1)\n",
        "y = dataset['lab_el']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .20)\n",
        "from sklearn.svm import SVC\n",
        "svclassifier=SVC(probability=True)\n",
        "svclassifier.fit(x_train, y_train)\n",
        "y_pred = svclassifier.predict(x_test)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_pred,y_test))\n",
        "print(\"confusion matrix\")\n",
        "print(confusion_matrix(y_pred,y_test))\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input/\")\n",
        "\n",
        "from joblib import dump, load\n",
        "#to save model\n",
        "dump(svclassifier, 'svm_offensive.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--oqWk2QDDEb"
      },
      "source": [
        "SVM(With PCA)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC0L5wjjDJwD"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import pandas as pd\n",
        "dataset=pd.read_csv(\"/content/drive/My Drive/Hate Speech Detection/Project Codes/unigramSvmInput/neutral.csv\")\n",
        "X = dataset.drop('lab_el', axis=1)\n",
        "y = dataset['lab_el']\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "classifier = SVC()\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.3,random_state=4)\n",
        "pca = PCA()\n",
        "X_transformed = pca.fit_transform(X_train)\n",
        "classifier.fit(X_transformed, y_train)\n",
        "newdata_transformed = pca.transform(X_test)\n",
        "pred_labels = classifier.predict(newdata_transformed)\n",
        "print(\"pred_labels\\n\",pred_labels)\n",
        "print(classification_report(y_test,pred_labels))\n",
        "print(\"confusion matrix\")\n",
        "print(confusion_matrix(y_test,pred_labels))\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input/\")\n",
        "\n",
        "from joblib import dump, load\n",
        "#to save model\n",
        "dump(classifier, 'svm_pca_neutral.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6QeriLeDQo2"
      },
      "source": [
        "SVM(With TFIDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIKvhahZDUwt"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import re  \n",
        "import nltk \n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Hate Speech Detection/Project Codes/naive inp.csv\")\n",
        "def removeSpaces(dataset):\n",
        "  ret = []\n",
        "  for data in dataset:\n",
        "    ret.append(data.strip())\n",
        "\n",
        "  return ret\n",
        "\n",
        "X = dataset.drop('class',axis=1)\n",
        "x = list(X[\"tweet\"])\n",
        "X = removeSpaces(x)\n",
        "y = list(dataset['class'])\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "X = count.fit_transform(X)\n",
        " \n",
        "tfidfconverter = TfidfTransformer()  \n",
        "X = tfidfconverter.fit_transform(X).toarray()\n",
        "y_ = np.array(y)\n",
        "from sklearn.model_selection import train_test_split  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_, test_size=0.3, random_state=4)\n",
        "from sklearn.svm import SVC\n",
        "text_classifier = SVC(kernel='linear',probability=True)  \n",
        "text_classifier.fit(X_train, y_train)\n",
        "predictions = text_classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,predictions))  \n",
        "print(classification_report(y_test,predictions))  \n",
        "print(accuracy_score(y_test, predictions))\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input/\")\n",
        "\n",
        "from joblib import dump, load\n",
        "#to save model\n",
        "dump(text_classifier, 'tfidf.joblib')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvfP84S8mac5"
      },
      "source": [
        "\n",
        "random forest pca\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN-MUtx2SolP"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "#load the data set\n",
        "dataset=pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/unigramSvmInput/offensive.csv')\n",
        "\n",
        "#load the data set\n",
        "\n",
        "X=dataset.drop('lab_el',axis=1)\n",
        "y=dataset['lab_el']\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "\n",
        "# initiate PCA and classifier\n",
        "pca = PCA()\n",
        "classifier = RandomForestClassifier()\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.3,random_state=4)\n",
        "\n",
        "# transform / fit \t\t\t[a x1+b x2+c x3……..]\n",
        "X_transformed = pca.fit_transform(X_train)\n",
        "classifier.fit(X_transformed, y_train)\n",
        "\n",
        "# predict \"new\" data\n",
        "# transform new data using already fitted pca\n",
        "#X is projected on the first principal components previously extracted from a training set.\n",
        "newdata_transformed = pca.transform(X_test)\n",
        "\n",
        "# predict labels using the trained classifier\n",
        "pred_labels = classifier.predict(newdata_transformed)\n",
        "print(pred_labels)\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(pred_labels,y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcN6qUuUW2yH"
      },
      "source": [
        "from sklearn import model_selection\n",
        "rfc=RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)\n",
        "rfc_predict=rfc.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWD2M81xfmp7"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test,rfc_predict))\n",
        "print(confusion_matrix(y_test,rfc_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqRGVw5RVXSf"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input')\n",
        "from joblib import dump,load\n",
        "dump(classifier,'rf_offensive_pca.joblib')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbTtlmhInfmJ"
      },
      "source": [
        "random forest wo pca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UvjYP9_1DlU"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/unigramSvmInput/hate.csv')\n",
        "print(df.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG_2Nfei1WxY"
      },
      "source": [
        "X=df.drop('lab_el',axis=1)\n",
        "y=df['lab_el']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dPmRwlB1jxF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP560OSa3L-Y"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc=RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)\n",
        "rfc_predict=rfc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDa4f5rQvH7p"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test,rfc_predict))\n",
        "print(classification_report(y_test,rfc_predict))\n",
        "print(accuracy_score(y_test,rfc_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqwoeBlcw_1C"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input/\")\n",
        "from joblib import dump,load\n",
        "dump(rfc,'rf_hate.joblib')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFLfAvIznF4l"
      },
      "source": [
        "**DECISION TREE WITHOUT PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc3QDksZnFKP"
      },
      "source": [
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#load the data set\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/unigramSvmInput/neutral.csv')\n",
        "print(dataset)\n",
        "X = dataset.drop('lab_el',axis=1)\n",
        "print(X)\n",
        "y = dataset['lab_el']\n",
        "#print(X.shape)\n",
        "#print(y.shape)\n",
        "\n",
        "print(\"Data fetch phase complete\")\n",
        "\n",
        "sc=StandardScaler()\n",
        "pca = PCA()\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.3,random_state=4)\n",
        "\n",
        "\n",
        "#X_transformed = sc.fit_transform(X_train)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "#print(\"X is transformed....\")\n",
        "# predict \"new\" data\n",
        "# transform new data using already fitted sc\n",
        "#X is projected on the first principal components previously extracted from a training set.\n",
        "#newdata_transformed = sc.transform(X_test)\n",
        "\n",
        "# predict labels using the trained classifier\n",
        "\n",
        "print(\"Predicting the labels....\")\n",
        "pred_labels = classifier.predict(X_test)\n",
        "print(pred_labels)\n",
        "\n",
        "\n",
        "print(\"Accuracy printing....\")\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_test,pred_labels))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZyFt5Rjs9rR"
      },
      "source": [
        "\n",
        "LOGISTIC REGRESSION { Binary classification - wheather tweet is true or fals(hate,neutral,offensive) can only be predicted here }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9BTwW2rtCMx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from scipy import sparse\n",
        "%matplotlib inline\n",
        "seed = 42\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = '4'\n",
        "\n",
        "\n",
        "#Read data set\n",
        "train = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/demo_inp.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Hate Speech Detection/Project Codes/naive inp.csv')\n",
        "\n",
        "#Text preprosesing(word and character wise)\n",
        "vect_word = TfidfVectorizer(max_features=20000, lowercase=True, analyzer='word',\n",
        "                        stop_words= 'english',ngram_range=(1,3),dtype=np.float32)\n",
        "vect_char = TfidfVectorizer(max_features=40000, lowercase=True, analyzer='char',\n",
        "                        stop_words= 'english',ngram_range=(3,6),dtype=np.float32)\n",
        "\n",
        "tr_vect = vect_word.fit_transform(train['tweet'])\n",
        "ts_vect = vect_word.transform(test['tweet'])\n",
        "\n",
        "# Character n gram vector\n",
        "tr_vect_char = vect_char.fit_transform(train['tweet'])\n",
        "ts_vect_char = vect_char.transform(test['tweet'])\n",
        "gc.collect()\n",
        "\n",
        "#stacking training and testing vector together\n",
        "X = sparse.hstack([tr_vect, tr_vect_char])\n",
        "x_test = sparse.hstack([ts_vect, ts_vect_char])\n",
        "\n",
        "target_col = ['hate','neutral','offensive']\n",
        "y = train[target_col]\n",
        "#print(len(y))\n",
        "#print(x_test.shape)\n",
        "del tr_vect, ts_vect, tr_vect_char, ts_vect_char\n",
        "gc.collect()\n",
        "\n",
        "prd = np.zeros((x_test.shape[0],y.shape[1]))\n",
        "#print(prd)\n",
        "cv_score =[]\n",
        "models = {}\n",
        "for i,col in enumerate(target_col):\n",
        "    lr = LogisticRegression(C=2,random_state = i,class_weight = 'balanced')\n",
        "    print('Building {} model for column:{''}'.format(i,col)) \n",
        "    lr.fit(X,y[col])#hate\n",
        "    #save code\n",
        "    \n",
        "    #hate , neutral , offensive\n",
        "    #saving model to a list\n",
        "    models[col] = lr\n",
        "    #cv_score.append(lr.score)\n",
        "    prd[:,i] = lr.predict_proba(x_test)[:,1]  #[55%,44%]  [not hate:hate:yes]\n",
        "\n",
        "hate_model = models['hate']\n",
        "offensive_model = models['offensive']\n",
        "neutral_model = models['neutral']\n",
        "\n",
        "#Model Validation on train data set\n",
        "col = 'offensive'\n",
        "print(\"Column:\",col)\n",
        "pred =  offensive_model.predict(X)\n",
        "print('\\nConfusion matrix\\n',confusion_matrix(y[col],pred))\n",
        "print(classification_report(y[col],pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qyo0ccatGHB"
      },
      "source": [
        "VOTING CLASSIFIER / STACKING CLASSIFIER (XG-BOOST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbSvqYqktJfC"
      },
      "source": [
        "import json\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from joblib import dump, load\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"fetching dataset...\\n\")\n",
        "#importing data\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Hate Speech Detection/Project Codes/naive inp.csv\")\n",
        "\n",
        "\n",
        "vect = CountVectorizer()\n",
        "tf = TfidfTransformer()\n",
        "#function to remove blank spaces(starting) in each line\n",
        "def removeSpaces(dataset):\n",
        "  ret = []\n",
        "  for data in dataset:\n",
        "    ret.append(data.strip())\n",
        "\n",
        "  return ret\n",
        "\n",
        "\n",
        "X = dataset.drop('class',axis=1)\n",
        "y = dataset['class']\n",
        "X = list(X[\"tweet\"])\n",
        "X = removeSpaces(X)\n",
        "y = list(dataset['class'])\n",
        "\n",
        "X = vect.fit_transform(X)\n",
        "\n",
        "X = tf.fit_transform(X)\n",
        "\n",
        "X = X.toarray()\n",
        "\n",
        "# function to load models from file\n",
        "def loadAllModels(paths):\n",
        "\n",
        "\tall_models = []\n",
        "\n",
        "\tfor path in paths:\n",
        "\t\t#to load model\n",
        "\t\tclf = load(path)\n",
        "\t\t#appending to the list\n",
        "\t\tall_models.append(clf)\n",
        "\n",
        "\treturn all_models\n",
        "\n",
        "# function to create stacked model input dataset as outputs from the ensemble\n",
        "def stacked_dataset(members, inputX):\n",
        "\n",
        "\tstackX = None\n",
        "\n",
        "\tfor model in members:\n",
        "\t\t# make prediction\n",
        "\t\tpred = model.predict_proba(inputX)\n",
        "\t\t# stack predictions into [rows, members, probabilities]\n",
        "\t\tif stackX is None:\n",
        "\t\t\tstackX = pred\n",
        "\t\telse:\n",
        "\t\t\tstackX = np.dstack((stackX, pred))\n",
        "\t# flatten predictions to [rows, members x probabilities]\n",
        "\t############################################################\n",
        "\t#in our case the predictions from the individual model will\n",
        "\t#be an array with shape (tweets,classess) and after stacking all\n",
        "\t#the predictions into stackX the shape of stackX will be\n",
        "\t#(tweets,4,classes). Since the last two metrics ie 4 and 3\n",
        "  #represent features from four classifiers, these two metrics\n",
        "  #are going to be flattered(multiplies/reshaped) into (tweets,4*3)\n",
        "  #which is (tweets,12)\n",
        "\n",
        "\t#(24000,3)\t : 24000 is the number of samples and 3 is the number\n",
        "\t#\t\t\t   of classes\n",
        "\t#(24000,4,3): 24000 is the number of samples, 4 is the number of models\n",
        "\t#\t\t\t   and 3 number of classes\n",
        "\t############################################################\n",
        "\tstackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
        "\n",
        "\treturn stackX\n",
        "\n",
        "paths = [\"/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input/GaussianNB_tfidf.joblib\",\n",
        "         \"/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input/decisiontree_tfid.joblib\",\n",
        "         \"/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input/rf_tfidf.joblib\"]\n",
        "         #\"/content/drive/My Drive/Hate Speech Detection/Project Codes/Voting_input/svm_neutral.joblib\"]\n",
        "\n",
        "print(\"loading models...\\n\")\n",
        "all_models = loadAllModels(paths)\n",
        "\n",
        "print(\"stacking the predictions...\\n\")\n",
        "all_predictions = stacked_dataset(all_models, X)\n",
        "\n",
        "print(\"done...\\n\")\n",
        "\n",
        "clf = XGBClassifier()\n",
        "\n",
        "#training\n",
        "clf.fit(all_predictions,y)\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Model Validation on train data set\n",
        "print(classification_report(y,clf.predict(all_predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}